{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_PATH = \"./dataset/train/\"\n",
    "# VAL_DATASET_PATH = \"./valid/\"\n",
    "# TEST_DATASET_PATH = \"./test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>labels</th>\n",
       "      <th>x_center</th>\n",
       "      <th>y_center</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>009000_jpg.rf.8c46e1aa5b46a0ad24ee4bcb2945d22a...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[0.6538461538461539]</td>\n",
       "      <td>[0.5420673076923077]</td>\n",
       "      <td>[0.0625]</td>\n",
       "      <td>[0.06610576923076923]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>009002_jpg.rf.18bf80f2cfdb51f853da15019f787cef...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[0.5576923076923077]</td>\n",
       "      <td>[0.3389423076923077]</td>\n",
       "      <td>[0.055288461538461536]</td>\n",
       "      <td>[0.07091346153846154]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>009003_jpg.rf.46963402c4cb6f46a47e508b892c6521...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[0.4230769230769231]</td>\n",
       "      <td>[0.3798076923076923]</td>\n",
       "      <td>[0.09975961538461539]</td>\n",
       "      <td>[0.055288461538461536]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>009007_jpg.rf.a5143afbb0c741f3b60fc72403fdde6a...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[0.4014423076923077]</td>\n",
       "      <td>[0.35096153846153844]</td>\n",
       "      <td>[0.055288461538461536]</td>\n",
       "      <td>[0.1778846153846154]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009012_jpg.rf.bc99877ade8754d2be89119361e7820c...</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[0.8040865384615384]</td>\n",
       "      <td>[0.3870192307692308]</td>\n",
       "      <td>[0.052884615384615384]</td>\n",
       "      <td>[0.07211538461538461]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6176</th>\n",
       "      <td>042973_jpg.rf.6792837ba2183435721cd7b4e9674ecd...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.3485576923076923]</td>\n",
       "      <td>[0.3016826923076923]</td>\n",
       "      <td>[0.08533653846153846]</td>\n",
       "      <td>[0.08653846153846154]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6177</th>\n",
       "      <td>042982_jpg.rf.79a8b11af76f74faa44312da78ee1486...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[0.3629807692307692]</td>\n",
       "      <td>[0.5276442307692307]</td>\n",
       "      <td>[0.0625]</td>\n",
       "      <td>[0.16706730769230768]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6178</th>\n",
       "      <td>042984_jpg.rf.5005cade401420afa36aac4b818e8dfa...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.3870192307692308]</td>\n",
       "      <td>[0.36778846153846156]</td>\n",
       "      <td>[0.04447115384615385]</td>\n",
       "      <td>[0.052884615384615384]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6179</th>\n",
       "      <td>042994_jpg.rf.141176d36edf4a11d33dad95a76e61b6...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.5084134615384616]</td>\n",
       "      <td>[0.5492788461538461]</td>\n",
       "      <td>[0.0889423076923077]</td>\n",
       "      <td>[0.06370192307692307]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180</th>\n",
       "      <td>042996_jpg.rf.09fa6ea27e4110355c4cc9c938e71419...</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[0.7764423076923077]</td>\n",
       "      <td>[0.6189903846153846]</td>\n",
       "      <td>[0.051682692307692304]</td>\n",
       "      <td>[0.11538461538461539]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6181 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 images labels  \\\n",
       "0     009000_jpg.rf.8c46e1aa5b46a0ad24ee4bcb2945d22a...    [2]   \n",
       "1     009002_jpg.rf.18bf80f2cfdb51f853da15019f787cef...    [2]   \n",
       "2     009003_jpg.rf.46963402c4cb6f46a47e508b892c6521...    [2]   \n",
       "3     009007_jpg.rf.a5143afbb0c741f3b60fc72403fdde6a...    [2]   \n",
       "4     009012_jpg.rf.bc99877ade8754d2be89119361e7820c...    [2]   \n",
       "...                                                 ...    ...   \n",
       "6176  042973_jpg.rf.6792837ba2183435721cd7b4e9674ecd...    [1]   \n",
       "6177  042982_jpg.rf.79a8b11af76f74faa44312da78ee1486...    [4]   \n",
       "6178  042984_jpg.rf.5005cade401420afa36aac4b818e8dfa...    [1]   \n",
       "6179  042994_jpg.rf.141176d36edf4a11d33dad95a76e61b6...    [1]   \n",
       "6180  042996_jpg.rf.09fa6ea27e4110355c4cc9c938e71419...    [4]   \n",
       "\n",
       "                  x_center               y_center                   width  \\\n",
       "0     [0.6538461538461539]   [0.5420673076923077]                [0.0625]   \n",
       "1     [0.5576923076923077]   [0.3389423076923077]  [0.055288461538461536]   \n",
       "2     [0.4230769230769231]   [0.3798076923076923]   [0.09975961538461539]   \n",
       "3     [0.4014423076923077]  [0.35096153846153844]  [0.055288461538461536]   \n",
       "4     [0.8040865384615384]   [0.3870192307692308]  [0.052884615384615384]   \n",
       "...                    ...                    ...                     ...   \n",
       "6176  [0.3485576923076923]   [0.3016826923076923]   [0.08533653846153846]   \n",
       "6177  [0.3629807692307692]   [0.5276442307692307]                [0.0625]   \n",
       "6178  [0.3870192307692308]  [0.36778846153846156]   [0.04447115384615385]   \n",
       "6179  [0.5084134615384616]   [0.5492788461538461]    [0.0889423076923077]   \n",
       "6180  [0.7764423076923077]   [0.6189903846153846]  [0.051682692307692304]   \n",
       "\n",
       "                      height  \n",
       "0      [0.06610576923076923]  \n",
       "1      [0.07091346153846154]  \n",
       "2     [0.055288461538461536]  \n",
       "3       [0.1778846153846154]  \n",
       "4      [0.07211538461538461]  \n",
       "...                      ...  \n",
       "6176   [0.08653846153846154]  \n",
       "6177   [0.16706730769230768]  \n",
       "6178  [0.052884615384615384]  \n",
       "6179   [0.06370192307692307]  \n",
       "6180   [0.11538461538461539]  \n",
       "\n",
       "[6181 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = TRAIN_DATASET_PATH + \"labels\"\n",
    "\n",
    "dct = {\n",
    "    \"images\": [],\n",
    "    \"labels\": [],\n",
    "    \"x_center\": [],\n",
    "    \"y_center\": [],\n",
    "    \"width\": [],\n",
    "    \"height\": []\n",
    "}\n",
    "\n",
    "for image in os.listdir(path):\n",
    "    label_file = open(path + \"/\" + image)\n",
    "\n",
    "    labels_str = label_file.read().split(sep=\"\\n\")\n",
    "    labels_arr = []\n",
    "    xmin_arr = []\n",
    "    ymin_arr = []\n",
    "    xmax_arr = []\n",
    "    ymax_arr = []\n",
    "    for label in labels_str:\n",
    "        label_parts = label.split()\n",
    "        labels_arr.append(int(label_parts[0]))\n",
    "        xmin_arr.append(float(label_parts[1]))\n",
    "        ymin_arr.append(float(label_parts[2]))\n",
    "        xmax_arr.append(float(label_parts[3]))\n",
    "        ymax_arr.append(float(label_parts[4]))\n",
    "\n",
    "    dct[\"images\"].append(image)\n",
    "    dct[\"labels\"].append(labels_arr)\n",
    "    dct[\"x_center\"].append(xmin_arr)\n",
    "    dct[\"y_center\"].append(ymin_arr)\n",
    "    dct[\"width\"].append(xmax_arr)\n",
    "    dct[\"height\"].append(ymax_arr)\n",
    "\n",
    "    label_file.close()\n",
    "\n",
    "df = pd.DataFrame(dct)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>labels</th>\n",
       "      <th>x_center</th>\n",
       "      <th>y_center</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>009696_jpg.rf.cce06a15455bdfb3ec994de61207f9ec...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.7295673076923077]</td>\n",
       "      <td>[0.49399038461538464]</td>\n",
       "      <td>[0.13822115384615385]</td>\n",
       "      <td>[0.0829326923076923]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>020535_jpg.rf.1d1f389c1ac9223533b07f19d45d0fed...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.5276442307692307]</td>\n",
       "      <td>[0.3401442307692308]</td>\n",
       "      <td>[0.09254807692307693]</td>\n",
       "      <td>[0.12740384615384615]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>026032_jpg.rf.7e9a535ddcf0a5013b8c37dffd3739af...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.5204326923076923]</td>\n",
       "      <td>[0.5072115384615384]</td>\n",
       "      <td>[0.06490384615384616]</td>\n",
       "      <td>[0.06971153846153846]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>026040_jpg.rf.308b8bcf0f012196737af0715b064cbb...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.6442307692307693]</td>\n",
       "      <td>[0.49399038461538464]</td>\n",
       "      <td>[0.06490384615384616]</td>\n",
       "      <td>[0.11658653846153846]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>026043_jpg.rf.4e6258a0c6557491c1a7619d51f48834...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.3245192307692308]</td>\n",
       "      <td>[0.5552884615384616]</td>\n",
       "      <td>[0.03245192307692308]</td>\n",
       "      <td>[0.14783653846153846]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>026057_jpg.rf.97d02180613f5ffe322d1cbf89d34031...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.5829326923076923]</td>\n",
       "      <td>[0.3894230769230769]</td>\n",
       "      <td>[0.11177884615384616]</td>\n",
       "      <td>[0.07211538461538461]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>026074_jpg.rf.7d4a4263d7461b4688a8548deb37ac09...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.6129807692307693]</td>\n",
       "      <td>[0.5180288461538461]</td>\n",
       "      <td>[0.07692307692307693]</td>\n",
       "      <td>[0.11899038461538461]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>026107_jpg.rf.24622a90c94e31cb97327d1b711882b2...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.46033653846153844]</td>\n",
       "      <td>[0.5096153846153846]</td>\n",
       "      <td>[0.02403846153846154]</td>\n",
       "      <td>[0.14543269230769232]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>026127_jpg.rf.ddfedfe6d2728271fefebe522bbfaca0...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.59375]</td>\n",
       "      <td>[0.3293269230769231]</td>\n",
       "      <td>[0.06009615384615385]</td>\n",
       "      <td>[0.052884615384615384]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>026135_jpg.rf.1b7417b83015da5e83efcfb417a00623...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.6382211538461539]</td>\n",
       "      <td>[0.5120192307692307]</td>\n",
       "      <td>[0.06850961538461539]</td>\n",
       "      <td>[0.125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>026141_jpg.rf.57ef360fe502943ad1e477b370bf2274...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.3401442307692308]</td>\n",
       "      <td>[0.49158653846153844]</td>\n",
       "      <td>[0.039663461538461536]</td>\n",
       "      <td>[0.14423076923076922]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>026148_jpg.rf.576abfc9253663bcac3847ac9ea57ee4...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.6141826923076923]</td>\n",
       "      <td>[0.4795673076923077]</td>\n",
       "      <td>[0.10697115384615384]</td>\n",
       "      <td>[0.07451923076923077]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>026167_jpg.rf.cc7b229ec5e29327571d07ffe010f001...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.5637019230769231]</td>\n",
       "      <td>[0.49158653846153844]</td>\n",
       "      <td>[0.057692307692307696]</td>\n",
       "      <td>[0.06971153846153846]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>026171_jpg.rf.91f06b523bad9873e77d9abccd71908a...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.6117788461538461]</td>\n",
       "      <td>[0.41346153846153844]</td>\n",
       "      <td>[0.056490384615384616]</td>\n",
       "      <td>[0.06129807692307692]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>026173_jpg.rf.1faea44faa2949f3ae1b08cc7630f111...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.5348557692307693]</td>\n",
       "      <td>[0.4639423076923077]</td>\n",
       "      <td>[0.055288461538461536]</td>\n",
       "      <td>[0.16105769230769232]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>026184_jpg.rf.4b3cdc674c2c10809bad2cebb4b4fc8e...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.6598557692307693]</td>\n",
       "      <td>[0.5685096153846154]</td>\n",
       "      <td>[0.12740384615384615]</td>\n",
       "      <td>[0.0673076923076923]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>026193_jpg.rf.c579ded043020b484e13b0080f8b99f9...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.5997596153846154]</td>\n",
       "      <td>[0.484375]</td>\n",
       "      <td>[0.06610576923076923]</td>\n",
       "      <td>[0.08653846153846154]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>026204_jpg.rf.09ed6893460c38a4e3bc197c4ec54a99...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.6177884615384616]</td>\n",
       "      <td>[0.4495192307692308]</td>\n",
       "      <td>[0.125]</td>\n",
       "      <td>[0.036057692307692304]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>026231_jpg.rf.fc0c7f43c7f49648cb0606e324f4b044...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.6430288461538461]</td>\n",
       "      <td>[0.53125]</td>\n",
       "      <td>[0.12139423076923077]</td>\n",
       "      <td>[0.06610576923076923]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>026262_jpg.rf.1169b6e1f1f7a29d8eadf93964487ab4...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.0889423076923077]</td>\n",
       "      <td>[0.6213942307692307]</td>\n",
       "      <td>[0.11177884615384616]</td>\n",
       "      <td>[0.04567307692307692]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>026268_jpg.rf.1294bdf51fc2801cf65741f0b5730709...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.7788461538461539]</td>\n",
       "      <td>[0.6766826923076923]</td>\n",
       "      <td>[0.12980769230769232]</td>\n",
       "      <td>[0.037259615384615384]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>026270_jpg.rf.a83ba6d7fda6ad09ed734d12bda93b62...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.2536057692307692]</td>\n",
       "      <td>[0.5348557692307693]</td>\n",
       "      <td>[0.04567307692307692]</td>\n",
       "      <td>[0.13221153846153846]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>026271_jpg.rf.16e2af62c036568da310acdf1478e534...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.4987980769230769]</td>\n",
       "      <td>[0.39903846153846156]</td>\n",
       "      <td>[0.038461538461538464]</td>\n",
       "      <td>[0.09375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>026275_jpg.rf.a33d8c9e7c92f25d2986368f5ebfb69f...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.5805288461538461]</td>\n",
       "      <td>[0.4206730769230769]</td>\n",
       "      <td>[0.12139423076923077]</td>\n",
       "      <td>[0.052884615384615384]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>026276_jpg.rf.ed38c05e20980acc226e2145ac22e81a...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.5480769230769231]</td>\n",
       "      <td>[0.5240384615384616]</td>\n",
       "      <td>[0.109375]</td>\n",
       "      <td>[0.037259615384615384]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>026281_jpg.rf.82ddb79b8ebccf9ac1802cdf3eb7f2ba...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.6057692307692307]</td>\n",
       "      <td>[0.5444711538461539]</td>\n",
       "      <td>[0.11177884615384616]</td>\n",
       "      <td>[0.078125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>026318_jpg.rf.00150f39740280b34262ee3ad0d20d0b...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.4543269230769231]</td>\n",
       "      <td>[0.5612980769230769]</td>\n",
       "      <td>[0.06610576923076923]</td>\n",
       "      <td>[0.07932692307692307]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>026325_jpg.rf.0b5a4eafa30f6cee09adfb0a1f4c1536...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.5264423076923077]</td>\n",
       "      <td>[0.6586538461538461]</td>\n",
       "      <td>[0.10576923076923077]</td>\n",
       "      <td>[0.1310096153846154]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>026335_jpg.rf.da59b875035a1bc1a15cc835a7cafc69...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.3954326923076923]</td>\n",
       "      <td>[0.43990384615384615]</td>\n",
       "      <td>[0.07451923076923077]</td>\n",
       "      <td>[0.06129807692307692]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>026365_jpg.rf.01f495ac18b7aaac192ff368ef42fb00...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.5793269230769231]</td>\n",
       "      <td>[0.3942307692307692]</td>\n",
       "      <td>[0.09975961538461539]</td>\n",
       "      <td>[0.06490384615384616]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>026399_jpg.rf.27cd852cb414c5769954b613d456c44f...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.3737980769230769]</td>\n",
       "      <td>[0.43028846153846156]</td>\n",
       "      <td>[0.04807692307692308]</td>\n",
       "      <td>[0.06129807692307692]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>026413_jpg.rf.ed43a7bf692c9cdc556f1dcc674ad95a...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.6610576923076923]</td>\n",
       "      <td>[0.49038461538461536]</td>\n",
       "      <td>[0.078125]</td>\n",
       "      <td>[0.06129807692307692]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>026427_jpg.rf.5d18b3af75b3e4887f06ab745d8edf08...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.734375]</td>\n",
       "      <td>[0.46875]</td>\n",
       "      <td>[0.08052884615384616]</td>\n",
       "      <td>[0.06850961538461539]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>026446_jpg.rf.beaa2bbb8b81f4c6ba6ab3935d43e40d...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.6382211538461539]</td>\n",
       "      <td>[0.5228365384615384]</td>\n",
       "      <td>[0.06490384615384616]</td>\n",
       "      <td>[0.06490384615384616]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>026469_jpg.rf.df1deb8f4cb012f88b4a801d64698df4...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.6899038461538461]</td>\n",
       "      <td>[0.43990384615384615]</td>\n",
       "      <td>[0.11538461538461539]</td>\n",
       "      <td>[0.07091346153846154]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>026474_jpg.rf.2cd98736543f64c9fdf49529b01a8eb6...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.7536057692307693]</td>\n",
       "      <td>[0.31850961538461536]</td>\n",
       "      <td>[0.078125]</td>\n",
       "      <td>[0.07932692307692307]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>026499_jpg.rf.8d97b5b265aec0a67ddeeee9b75df90b...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.6153846153846154]</td>\n",
       "      <td>[0.390625]</td>\n",
       "      <td>[0.038461538461538464]</td>\n",
       "      <td>[0.07572115384615384]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>026537_jpg.rf.a890d27a5efaee411c4a476c1158fb09...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.3125]</td>\n",
       "      <td>[0.5901442307692307]</td>\n",
       "      <td>[0.10336538461538461]</td>\n",
       "      <td>[0.040865384615384616]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>026538_jpg.rf.7dee7559ae40cfe8e5b337973bacfab3...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.18389423076923078]</td>\n",
       "      <td>[0.37740384615384615]</td>\n",
       "      <td>[0.054086538461538464]</td>\n",
       "      <td>[0.14903846153846154]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>026547_jpg.rf.042ddd08ad8e830fd85e8131f8ac3951...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.5420673076923077]</td>\n",
       "      <td>[0.390625]</td>\n",
       "      <td>[0.07932692307692307]</td>\n",
       "      <td>[0.15264423076923078]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>026554_jpg.rf.7b3557e9a369b0c60d4ef33269b99148...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.5252403846153846]</td>\n",
       "      <td>[0.38461538461538464]</td>\n",
       "      <td>[0.14543269230769232]</td>\n",
       "      <td>[0.08413461538461539]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>026582_jpg.rf.5f685bc1887a5432889a9e2246ee71af...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.4651442307692308]</td>\n",
       "      <td>[0.5120192307692307]</td>\n",
       "      <td>[0.12139423076923077]</td>\n",
       "      <td>[0.0733173076923077]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>026600_jpg.rf.b2297ea94a6055610f9cbaceddb8d4dc...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.4254807692307692]</td>\n",
       "      <td>[0.5685096153846154]</td>\n",
       "      <td>[0.051682692307692304]</td>\n",
       "      <td>[0.057692307692307696]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>026609_jpg.rf.2b0482d92b6b9472e4c01ff2f3422d59...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.3557692307692308]</td>\n",
       "      <td>[0.5036057692307693]</td>\n",
       "      <td>[0.09254807692307693]</td>\n",
       "      <td>[0.04807692307692308]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>026626_jpg.rf.615db7a9571a51eb80028e2dea1890ac...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.5168269230769231]</td>\n",
       "      <td>[0.5576923076923077]</td>\n",
       "      <td>[0.0985576923076923]</td>\n",
       "      <td>[0.12139423076923077]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>026640_jpg.rf.4693b2c1a648edb179738115053f60ed...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.5024038461538461]</td>\n",
       "      <td>[0.4362980769230769]</td>\n",
       "      <td>[0.03485576923076923]</td>\n",
       "      <td>[0.1502403846153846]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>026641_jpg.rf.4277330ebbade7f2776adde680119ff7...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.4411057692307692]</td>\n",
       "      <td>[0.39302884615384615]</td>\n",
       "      <td>[0.06971153846153846]</td>\n",
       "      <td>[0.140625]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>026644_jpg.rf.a343df1dd0d968ca4874c6186f9c70bd...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.4951923076923077]</td>\n",
       "      <td>[0.3581730769230769]</td>\n",
       "      <td>[0.14423076923076922]</td>\n",
       "      <td>[0.08653846153846154]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>026674_jpg.rf.4c012750282f01ba139360042486c5ad...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.5588942307692307]</td>\n",
       "      <td>[0.5997596153846154]</td>\n",
       "      <td>[0.046875]</td>\n",
       "      <td>[0.09735576923076923]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>026677_jpg.rf.a04db4787f4cfcdcb54a797398c926d2...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.46153846153846156]</td>\n",
       "      <td>[0.49759615384615385]</td>\n",
       "      <td>[0.06971153846153846]</td>\n",
       "      <td>[0.11778846153846154]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 images labels  \\\n",
       "227   009696_jpg.rf.cce06a15455bdfb3ec994de61207f9ec...    [1]   \n",
       "1272  020535_jpg.rf.1d1f389c1ac9223533b07f19d45d0fed...    [1]   \n",
       "1986  026032_jpg.rf.7e9a535ddcf0a5013b8c37dffd3739af...    [1]   \n",
       "1990  026040_jpg.rf.308b8bcf0f012196737af0715b064cbb...    [1]   \n",
       "1991  026043_jpg.rf.4e6258a0c6557491c1a7619d51f48834...    [1]   \n",
       "1993  026057_jpg.rf.97d02180613f5ffe322d1cbf89d34031...    [1]   \n",
       "1994  026074_jpg.rf.7d4a4263d7461b4688a8548deb37ac09...    [1]   \n",
       "2000  026107_jpg.rf.24622a90c94e31cb97327d1b711882b2...    [1]   \n",
       "2003  026127_jpg.rf.ddfedfe6d2728271fefebe522bbfaca0...    [1]   \n",
       "2007  026135_jpg.rf.1b7417b83015da5e83efcfb417a00623...    [1]   \n",
       "2010  026141_jpg.rf.57ef360fe502943ad1e477b370bf2274...    [1]   \n",
       "2013  026148_jpg.rf.576abfc9253663bcac3847ac9ea57ee4...    [1]   \n",
       "2017  026167_jpg.rf.cc7b229ec5e29327571d07ffe010f001...    [1]   \n",
       "2018  026171_jpg.rf.91f06b523bad9873e77d9abccd71908a...    [1]   \n",
       "2019  026173_jpg.rf.1faea44faa2949f3ae1b08cc7630f111...    [1]   \n",
       "2022  026184_jpg.rf.4b3cdc674c2c10809bad2cebb4b4fc8e...    [1]   \n",
       "2025  026193_jpg.rf.c579ded043020b484e13b0080f8b99f9...    [1]   \n",
       "2029  026204_jpg.rf.09ed6893460c38a4e3bc197c4ec54a99...    [1]   \n",
       "2034  026231_jpg.rf.fc0c7f43c7f49648cb0606e324f4b044...    [1]   \n",
       "2040  026262_jpg.rf.1169b6e1f1f7a29d8eadf93964487ab4...    [1]   \n",
       "2041  026268_jpg.rf.1294bdf51fc2801cf65741f0b5730709...    [1]   \n",
       "2042  026270_jpg.rf.a83ba6d7fda6ad09ed734d12bda93b62...    [1]   \n",
       "2043  026271_jpg.rf.16e2af62c036568da310acdf1478e534...    [1]   \n",
       "2044  026275_jpg.rf.a33d8c9e7c92f25d2986368f5ebfb69f...    [1]   \n",
       "2045  026276_jpg.rf.ed38c05e20980acc226e2145ac22e81a...    [1]   \n",
       "2046  026281_jpg.rf.82ddb79b8ebccf9ac1802cdf3eb7f2ba...    [1]   \n",
       "2054  026318_jpg.rf.00150f39740280b34262ee3ad0d20d0b...    [1]   \n",
       "2056  026325_jpg.rf.0b5a4eafa30f6cee09adfb0a1f4c1536...    [1]   \n",
       "2060  026335_jpg.rf.da59b875035a1bc1a15cc835a7cafc69...    [1]   \n",
       "2065  026365_jpg.rf.01f495ac18b7aaac192ff368ef42fb00...    [1]   \n",
       "2073  026399_jpg.rf.27cd852cb414c5769954b613d456c44f...    [1]   \n",
       "2077  026413_jpg.rf.ed43a7bf692c9cdc556f1dcc674ad95a...    [1]   \n",
       "2081  026427_jpg.rf.5d18b3af75b3e4887f06ab745d8edf08...    [1]   \n",
       "2083  026446_jpg.rf.beaa2bbb8b81f4c6ba6ab3935d43e40d...    [1]   \n",
       "2085  026469_jpg.rf.df1deb8f4cb012f88b4a801d64698df4...    [1]   \n",
       "2086  026474_jpg.rf.2cd98736543f64c9fdf49529b01a8eb6...    [1]   \n",
       "2091  026499_jpg.rf.8d97b5b265aec0a67ddeeee9b75df90b...    [1]   \n",
       "2098  026537_jpg.rf.a890d27a5efaee411c4a476c1158fb09...    [1]   \n",
       "2099  026538_jpg.rf.7dee7559ae40cfe8e5b337973bacfab3...    [1]   \n",
       "2102  026547_jpg.rf.042ddd08ad8e830fd85e8131f8ac3951...    [1]   \n",
       "2104  026554_jpg.rf.7b3557e9a369b0c60d4ef33269b99148...    [1]   \n",
       "2107  026582_jpg.rf.5f685bc1887a5432889a9e2246ee71af...    [1]   \n",
       "2110  026600_jpg.rf.b2297ea94a6055610f9cbaceddb8d4dc...    [1]   \n",
       "2114  026609_jpg.rf.2b0482d92b6b9472e4c01ff2f3422d59...    [1]   \n",
       "2116  026626_jpg.rf.615db7a9571a51eb80028e2dea1890ac...    [1]   \n",
       "2119  026640_jpg.rf.4693b2c1a648edb179738115053f60ed...    [1]   \n",
       "2120  026641_jpg.rf.4277330ebbade7f2776adde680119ff7...    [1]   \n",
       "2122  026644_jpg.rf.a343df1dd0d968ca4874c6186f9c70bd...    [1]   \n",
       "2127  026674_jpg.rf.4c012750282f01ba139360042486c5ad...    [1]   \n",
       "2128  026677_jpg.rf.a04db4787f4cfcdcb54a797398c926d2...    [1]   \n",
       "\n",
       "                   x_center               y_center                   width  \\\n",
       "227    [0.7295673076923077]  [0.49399038461538464]   [0.13822115384615385]   \n",
       "1272   [0.5276442307692307]   [0.3401442307692308]   [0.09254807692307693]   \n",
       "1986   [0.5204326923076923]   [0.5072115384615384]   [0.06490384615384616]   \n",
       "1990   [0.6442307692307693]  [0.49399038461538464]   [0.06490384615384616]   \n",
       "1991   [0.3245192307692308]   [0.5552884615384616]   [0.03245192307692308]   \n",
       "1993   [0.5829326923076923]   [0.3894230769230769]   [0.11177884615384616]   \n",
       "1994   [0.6129807692307693]   [0.5180288461538461]   [0.07692307692307693]   \n",
       "2000  [0.46033653846153844]   [0.5096153846153846]   [0.02403846153846154]   \n",
       "2003              [0.59375]   [0.3293269230769231]   [0.06009615384615385]   \n",
       "2007   [0.6382211538461539]   [0.5120192307692307]   [0.06850961538461539]   \n",
       "2010   [0.3401442307692308]  [0.49158653846153844]  [0.039663461538461536]   \n",
       "2013   [0.6141826923076923]   [0.4795673076923077]   [0.10697115384615384]   \n",
       "2017   [0.5637019230769231]  [0.49158653846153844]  [0.057692307692307696]   \n",
       "2018   [0.6117788461538461]  [0.41346153846153844]  [0.056490384615384616]   \n",
       "2019   [0.5348557692307693]   [0.4639423076923077]  [0.055288461538461536]   \n",
       "2022   [0.6598557692307693]   [0.5685096153846154]   [0.12740384615384615]   \n",
       "2025   [0.5997596153846154]             [0.484375]   [0.06610576923076923]   \n",
       "2029   [0.6177884615384616]   [0.4495192307692308]                 [0.125]   \n",
       "2034   [0.6430288461538461]              [0.53125]   [0.12139423076923077]   \n",
       "2040   [0.0889423076923077]   [0.6213942307692307]   [0.11177884615384616]   \n",
       "2041   [0.7788461538461539]   [0.6766826923076923]   [0.12980769230769232]   \n",
       "2042   [0.2536057692307692]   [0.5348557692307693]   [0.04567307692307692]   \n",
       "2043   [0.4987980769230769]  [0.39903846153846156]  [0.038461538461538464]   \n",
       "2044   [0.5805288461538461]   [0.4206730769230769]   [0.12139423076923077]   \n",
       "2045   [0.5480769230769231]   [0.5240384615384616]              [0.109375]   \n",
       "2046   [0.6057692307692307]   [0.5444711538461539]   [0.11177884615384616]   \n",
       "2054   [0.4543269230769231]   [0.5612980769230769]   [0.06610576923076923]   \n",
       "2056   [0.5264423076923077]   [0.6586538461538461]   [0.10576923076923077]   \n",
       "2060   [0.3954326923076923]  [0.43990384615384615]   [0.07451923076923077]   \n",
       "2065   [0.5793269230769231]   [0.3942307692307692]   [0.09975961538461539]   \n",
       "2073   [0.3737980769230769]  [0.43028846153846156]   [0.04807692307692308]   \n",
       "2077   [0.6610576923076923]  [0.49038461538461536]              [0.078125]   \n",
       "2081             [0.734375]              [0.46875]   [0.08052884615384616]   \n",
       "2083   [0.6382211538461539]   [0.5228365384615384]   [0.06490384615384616]   \n",
       "2085   [0.6899038461538461]  [0.43990384615384615]   [0.11538461538461539]   \n",
       "2086   [0.7536057692307693]  [0.31850961538461536]              [0.078125]   \n",
       "2091   [0.6153846153846154]             [0.390625]  [0.038461538461538464]   \n",
       "2098               [0.3125]   [0.5901442307692307]   [0.10336538461538461]   \n",
       "2099  [0.18389423076923078]  [0.37740384615384615]  [0.054086538461538464]   \n",
       "2102   [0.5420673076923077]             [0.390625]   [0.07932692307692307]   \n",
       "2104   [0.5252403846153846]  [0.38461538461538464]   [0.14543269230769232]   \n",
       "2107   [0.4651442307692308]   [0.5120192307692307]   [0.12139423076923077]   \n",
       "2110   [0.4254807692307692]   [0.5685096153846154]  [0.051682692307692304]   \n",
       "2114   [0.3557692307692308]   [0.5036057692307693]   [0.09254807692307693]   \n",
       "2116   [0.5168269230769231]   [0.5576923076923077]    [0.0985576923076923]   \n",
       "2119   [0.5024038461538461]   [0.4362980769230769]   [0.03485576923076923]   \n",
       "2120   [0.4411057692307692]  [0.39302884615384615]   [0.06971153846153846]   \n",
       "2122   [0.4951923076923077]   [0.3581730769230769]   [0.14423076923076922]   \n",
       "2127   [0.5588942307692307]   [0.5997596153846154]              [0.046875]   \n",
       "2128  [0.46153846153846156]  [0.49759615384615385]   [0.06971153846153846]   \n",
       "\n",
       "                      height  \n",
       "227     [0.0829326923076923]  \n",
       "1272   [0.12740384615384615]  \n",
       "1986   [0.06971153846153846]  \n",
       "1990   [0.11658653846153846]  \n",
       "1991   [0.14783653846153846]  \n",
       "1993   [0.07211538461538461]  \n",
       "1994   [0.11899038461538461]  \n",
       "2000   [0.14543269230769232]  \n",
       "2003  [0.052884615384615384]  \n",
       "2007                 [0.125]  \n",
       "2010   [0.14423076923076922]  \n",
       "2013   [0.07451923076923077]  \n",
       "2017   [0.06971153846153846]  \n",
       "2018   [0.06129807692307692]  \n",
       "2019   [0.16105769230769232]  \n",
       "2022    [0.0673076923076923]  \n",
       "2025   [0.08653846153846154]  \n",
       "2029  [0.036057692307692304]  \n",
       "2034   [0.06610576923076923]  \n",
       "2040   [0.04567307692307692]  \n",
       "2041  [0.037259615384615384]  \n",
       "2042   [0.13221153846153846]  \n",
       "2043               [0.09375]  \n",
       "2044  [0.052884615384615384]  \n",
       "2045  [0.037259615384615384]  \n",
       "2046              [0.078125]  \n",
       "2054   [0.07932692307692307]  \n",
       "2056    [0.1310096153846154]  \n",
       "2060   [0.06129807692307692]  \n",
       "2065   [0.06490384615384616]  \n",
       "2073   [0.06129807692307692]  \n",
       "2077   [0.06129807692307692]  \n",
       "2081   [0.06850961538461539]  \n",
       "2083   [0.06490384615384616]  \n",
       "2085   [0.07091346153846154]  \n",
       "2086   [0.07932692307692307]  \n",
       "2091   [0.07572115384615384]  \n",
       "2098  [0.040865384615384616]  \n",
       "2099   [0.14903846153846154]  \n",
       "2102   [0.15264423076923078]  \n",
       "2104   [0.08413461538461539]  \n",
       "2107    [0.0733173076923077]  \n",
       "2110  [0.057692307692307696]  \n",
       "2114   [0.04807692307692308]  \n",
       "2116   [0.12139423076923077]  \n",
       "2119    [0.1502403846153846]  \n",
       "2120              [0.140625]  \n",
       "2122   [0.08653846153846154]  \n",
       "2127   [0.09735576923076923]  \n",
       "2128   [0.11778846153846154]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"labels\"].isin([[1]])][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>009000_jpg.rf.8c46e1aa5b46a0ad24ee4bcb2945d22a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>009002_jpg.rf.18bf80f2cfdb51f853da15019f787cef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>009003_jpg.rf.46963402c4cb6f46a47e508b892c6521...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>009007_jpg.rf.a5143afbb0c741f3b60fc72403fdde6a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009012_jpg.rf.bc99877ade8754d2be89119361e7820c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6176</th>\n",
       "      <td>042973_jpg.rf.6792837ba2183435721cd7b4e9674ecd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6177</th>\n",
       "      <td>042982_jpg.rf.79a8b11af76f74faa44312da78ee1486...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6178</th>\n",
       "      <td>042984_jpg.rf.5005cade401420afa36aac4b818e8dfa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6179</th>\n",
       "      <td>042994_jpg.rf.141176d36edf4a11d33dad95a76e61b6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180</th>\n",
       "      <td>042996_jpg.rf.09fa6ea27e4110355c4cc9c938e71419...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6181 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 images\n",
       "0     009000_jpg.rf.8c46e1aa5b46a0ad24ee4bcb2945d22a...\n",
       "1     009002_jpg.rf.18bf80f2cfdb51f853da15019f787cef...\n",
       "2     009003_jpg.rf.46963402c4cb6f46a47e508b892c6521...\n",
       "3     009007_jpg.rf.a5143afbb0c741f3b60fc72403fdde6a...\n",
       "4     009012_jpg.rf.bc99877ade8754d2be89119361e7820c...\n",
       "...                                                 ...\n",
       "6176  042973_jpg.rf.6792837ba2183435721cd7b4e9674ecd...\n",
       "6177  042982_jpg.rf.79a8b11af76f74faa44312da78ee1486...\n",
       "6178  042984_jpg.rf.5005cade401420afa36aac4b818e8dfa...\n",
       "6179  042994_jpg.rf.141176d36edf4a11d33dad95a76e61b6...\n",
       "6180  042996_jpg.rf.09fa6ea27e4110355c4cc9c938e71419...\n",
       "\n",
       "[6181 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_path_df = pd.DataFrame({\n",
    "    \"images\": os.listdir(TRAIN_DATASET_PATH + \"images\")\n",
    "})\n",
    "\n",
    "images_path_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "index = 2110\n",
    "\n",
    "x_start = df[\"x_center\"][index][0] - df[\"width\"][index][0] / 2\n",
    "y_start = df[\"y_center\"][index][0] - df[\"height\"][index][0] / 2\n",
    "\n",
    "rect = patches.Rectangle((x_start * 416, y_start * 416), df[\"width\"][index][0] * 416, df[\"height\"][index][0] * 416, edgecolor=\"red\", facecolor=\"none\")\n",
    "\n",
    "ax.add_patch(rect)\n",
    "ax.imshow(Image.open(TRAIN_DATASET_PATH + \"images/\" + images_path_df[\"images\"][index]))\n",
    "print(df[\"labels\"][index][0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.plot(df[\"x_center\"][1993][0] * 416, df[\"y_center\"][1993][0] * 416, marker='o', markersize=2, color=\"red\")\n",
    "plt.imshow(Image.open(TRAIN_DATASET_PATH + \"images/\" + images_path_df[\"images\"][1993]))\n",
    "print(df[\"labels\"][1993][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: './train/labels/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m label_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./train/labels/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(label_dir, file), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      8\u001b[0m         lines \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: './train/labels/'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "label_dir = './train/labels/'\n",
    "class_counts = {}\n",
    "\n",
    "for file in os.listdir(label_dir):\n",
    "    with open(os.path.join(label_dir, file), 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) > 0:\n",
    "                class_id = int(parts[0])\n",
    "                class_counts[class_id] = class_counts.get(class_id, 0) + 1\n",
    "\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 118, 1: 193, 0: 166, 3: 203, 4: 203}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "label_dir = './test/labels/'\n",
    "class_counts = {}\n",
    "\n",
    "for file in os.listdir(label_dir):\n",
    "    with open(os.path.join(label_dir, file), 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) > 0:\n",
    "                class_id = int(parts[0])\n",
    "                class_counts[class_id] = class_counts.get(class_id, 0) + 1\n",
    "\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 225, 0: 391, 3: 366, 1: 389, 4: 395}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "label_dir = './valid/labels/'\n",
    "class_counts = {}\n",
    "\n",
    "for file in os.listdir(label_dir):\n",
    "    with open(os.path.join(label_dir, file), 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) > 0:\n",
    "                class_id = int(parts[0])\n",
    "                class_counts[class_id] = class_counts.get(class_id, 0) + 1\n",
    "\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:01<00:00, 6.24MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.137 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.136  Python-3.9.21 torch-2.7.0+cpu CPU (AMD Ryzen 5 5600 6-Core Processor)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=416, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\Zaky\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 5.07MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,823 parameters, 3,011,807 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 3.20.9 MB/s, size: 17.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Zaky\\Documents\\p2-final-project-ftds-hck-026\\train\\labels... 6181 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6181/6181 [00:04<00:00, 1456.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\Zaky\\Documents\\p2-final-project-ftds-hck-026\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.30.1 ms, read: 3.70.9 MB/s, size: 19.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zaky\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Zaky\\Documents\\p2-final-project-ftds-hck-026\\valid\\labels... 1766 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1766/1766 [00:01<00:00, 1450.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Zaky\\Documents\\p2-final-project-ftds-hck-026\\valid\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\Zaky\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30         0G      2.374      3.615      1.535         11        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:45<00:00,  1.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:54<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.484      0.369      0.326      0.114\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30         0G      2.141       2.46       1.44          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:47<00:00,  1.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:55<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.473      0.416      0.443      0.167\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30         0G       2.11      2.122      1.431          9        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:48<00:00,  1.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:55<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766       0.51      0.488      0.513      0.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30         0G      2.073      1.962      1.419         10        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:45<00:00,  1.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:54<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.606      0.459      0.436      0.154\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30         0G       2.04       1.84      1.397          8        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [12:21<00:00,  1.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [02:06<00:00,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.538      0.577      0.566       0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30         0G       2.02      1.773      1.381          8        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [18:28<00:00,  2.87s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [02:40<00:00,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766       0.62      0.634      0.651      0.262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30         0G      1.992      1.712      1.368          6        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [21:51<00:00,  3.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [02:33<00:00,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.742       0.59      0.661      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30         0G      1.975      1.661      1.362          8        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [23:43<00:00,  3.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [01:49<00:00,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.685      0.607      0.678      0.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30         0G      1.953      1.612      1.352          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [22:16<00:00,  3.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [02:21<00:00,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766       0.75      0.598       0.68      0.288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30         0G      1.938      1.561      1.343          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [10:05<00:00,  1.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:51<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766       0.67      0.605      0.653      0.275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30         0G      1.928      1.548      1.331          6        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:21<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:52<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.687      0.661      0.719      0.305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30         0G      1.928      1.516      1.333          9        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:30<00:00,  1.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:52<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.728      0.657      0.719      0.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30         0G      1.921      1.512      1.323         13        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:38<00:00,  1.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:51<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766       0.77      0.667      0.741      0.316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30         0G      1.905      1.462      1.322          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:27<00:00,  1.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:53<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.768      0.679      0.746      0.317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30         0G      1.903      1.438      1.323          8        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:36<00:00,  1.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:53<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.772      0.661      0.741      0.305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30         0G      1.883      1.447      1.305          7        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:37<00:00,  1.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:53<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.754      0.684      0.747      0.321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30         0G      1.866      1.405      1.294          7        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:35<00:00,  1.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:53<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.777      0.674      0.747      0.309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30         0G      1.872      1.395      1.303          7        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:36<00:00,  1.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:52<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.798      0.694      0.773      0.331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30         0G      1.855      1.365      1.291          7        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:38<00:00,  1.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:53<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766       0.79      0.691      0.763      0.334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30         0G      1.834      1.348       1.28          9        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:39<00:00,  1.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:53<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.816      0.717      0.776      0.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zaky\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "      21/30         0G      1.813      1.202       1.38          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:31<00:00,  1.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:53<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.804       0.71       0.79      0.353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30         0G      1.805      1.165      1.374          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:30<00:00,  1.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:53<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.801      0.724      0.798      0.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30         0G      1.789      1.139      1.373          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:26<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:53<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766       0.83       0.74      0.813      0.371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30         0G      1.781      1.112      1.359          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:24<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:53<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.839       0.74      0.818      0.371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30         0G      1.774      1.101      1.347          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:24<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:53<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.825      0.754      0.821      0.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30         0G      1.761      1.089      1.341          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:24<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:52<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.844      0.763      0.829      0.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30         0G      1.748      1.067      1.341          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:25<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:53<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.852      0.772      0.838      0.378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30         0G      1.746      1.036      1.332          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:25<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:53<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.839      0.772      0.836      0.381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30         0G      1.735      1.029      1.322          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:25<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:53<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.852      0.781      0.846      0.388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30         0G      1.727      1.011      1.323          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:24<00:00,  1.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:52<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.862       0.77      0.845      0.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 epochs completed in 5.397 hours.\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics 8.3.136  Python-3.9.21 torch-2.7.0+cpu CPU (AMD Ryzen 5 5600 6-Core Processor)\n",
      "Model summary (fused): 72 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:46<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.852      0.781      0.846      0.389\n",
      "                     0        391        391      0.967      0.971      0.977      0.528\n",
      "                     1        389        389      0.826      0.846      0.901      0.399\n",
      "                     2        225        225      0.776      0.476      0.622      0.223\n",
      "                     3        366        366      0.797       0.72        0.8      0.384\n",
      "                     4        395        395      0.895      0.891      0.928      0.409\n",
      "Speed: 0.6ms preprocess, 22.9ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0, 1, 2, 3, 4])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001D8822001C0>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,     0.05656,     0.02828,           0],\n",
       "       [          1,           1,           1, ...,    0.025839,    0.012919,           0],\n",
       "       [          1,           1,           1, ...,   0.0016707,  0.00083533,           0],\n",
       "       [          1,           1,           1, ...,   0.0038293,   0.0019147,           0],\n",
       "       [          1,           1,           1, ...,    0.023294,    0.011647,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[     0.4474,     0.44742,     0.52616, ...,           0,           0,           0],\n",
       "       [    0.18092,     0.18092,     0.22676, ...,           0,           0,           0],\n",
       "       [   0.064516,    0.064534,    0.094652, ...,           0,           0,           0],\n",
       "       [   0.099192,    0.099243,     0.14441, ...,           0,           0,           0],\n",
       "       [    0.25633,     0.25633,     0.30689, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.28902,     0.28904,     0.35832, ...,           1,           1,           1],\n",
       "       [   0.099536,    0.099536,     0.12805, ...,           1,           1,           1],\n",
       "       [    0.03338,    0.033389,     0.04978, ...,           1,           1,           1],\n",
       "       [   0.052261,    0.052289,    0.078087, ...,           1,           1,           1],\n",
       "       [    0.14728,     0.14728,     0.18168, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.98977,     0.98977,     0.98977, ...,           0,           0,           0],\n",
       "       [    0.99229,     0.99229,     0.98972, ...,           0,           0,           0],\n",
       "       [       0.96,        0.96,        0.96, ...,           0,           0,           0],\n",
       "       [    0.97268,     0.97268,     0.95902, ...,           0,           0,           0],\n",
       "       [    0.98734,     0.98734,     0.98734, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.43449995198053143\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.52844,      0.3993,      0.2234,     0.38392,     0.40906])\n",
       "names: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.8521368783319143, 'metrics/recall(B)': 0.780809684259822, 'metrics/mAP50(B)': 0.8455681441926212, 'metrics/mAP50-95(B)': 0.38882570840141034, 'fitness': 0.43449995198053143}\n",
       "save_dir: WindowsPath('runs/detect/train')\n",
       "speed: {'preprocess': 0.6086098527685633, 'inference': 22.909721970554095, 'loss': 5.770102395432962e-05, 'postprocess': 0.3106593997792705}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n",
    "model.train(data='data.yaml', epochs=30, imgsz=416, batch=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load your training results CSV\n",
    "df = pd.read_csv('runs/detect/train/results.csv')\n",
    "\n",
    "# Plot mAP metrics\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['epoch'], df['metrics/mAP50(B)'], label='mAP@0.5')\n",
    "plt.plot(df['epoch'], df['metrics/mAP50-95(B)'], label='mAP@0.5:0.95')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('mAP')\n",
    "plt.title('YOLOv8 Training Performance')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.136  Python-3.9.21 torch-2.7.0+cpu CPU (AMD Ryzen 5 5600 6-Core Processor)\n",
      "Model summary (fused): 72 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 119.739.4 MB/s, size: 17.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Zaky\\Documents\\p2-final-project-ftds-hck-026\\valid\\labels.cache... 1766 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1766/1766 [00:00<?, ?it/s]\n",
      "c:\\Users\\Zaky\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:42<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.852      0.781      0.846      0.389\n",
      "                     0        391        391      0.967      0.971      0.977      0.528\n",
      "                     1        389        389      0.826      0.846      0.901      0.399\n",
      "                     2        225        225      0.776      0.476      0.622      0.223\n",
      "                     3        366        366      0.797       0.72        0.8      0.384\n",
      "                     4        395        395      0.895      0.891      0.928      0.409\n",
      "Speed: 0.5ms preprocess, 21.0ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('runs/detect/train/weights/best.pt')\n",
    "metrics = model.val(data='data.yaml', imgsz=416, batch=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.138 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.136  Python-3.9.21 torch-2.7.0+cpu CPU (AMD Ryzen 5 5600 6-Core Processor)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=416, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,823 parameters, 3,011,807 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 2.90.8 MB/s, size: 17.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Zaky\\Documents\\p2-final-project-ftds-hck-026\\train\\labels.cache... 6181 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6181/6181 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.0 ms, read: 4.21.4 MB/s, size: 19.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\Zaky\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Zaky\\Documents\\p2-final-project-ftds-hck-026\\valid\\labels.cache... 1766 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1766/1766 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train2\\labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\Zaky\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train2\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20         0G      2.374      3.615      1.535         11        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:51<00:00,  1.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [01:00<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.484      0.369      0.326      0.114\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20         0G      2.141       2.47      1.434          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:15<00:00,  1.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:51<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.379      0.469      0.443      0.167\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20         0G      2.106      2.124       1.43          9        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:13<00:00,  1.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:51<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.481      0.485      0.472      0.187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20         0G       2.07      1.963      1.423         10        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:51<00:00,  1.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:56<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.641      0.486      0.498      0.182\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20         0G      2.033      1.846      1.388          8        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:41<00:00,  1.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:53<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.531      0.507      0.512      0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20         0G      2.006      1.749      1.372          8        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:31<00:00,  1.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:51<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.658      0.563      0.603      0.233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20         0G      1.983      1.702      1.357          6        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:16<00:00,  1.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:51<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.673      0.579      0.654      0.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20         0G      1.964      1.648       1.35          8        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:16<00:00,  1.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:51<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.719      0.575      0.675       0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20         0G      1.943      1.594      1.346          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:15<00:00,  1.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:51<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.761      0.602      0.693      0.292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20         0G      1.922      1.538      1.332          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:16<00:00,  1.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:51<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766       0.79      0.616      0.718      0.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zaky\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "      11/20         0G      1.868      1.393      1.422          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:11<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:51<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.762      0.629      0.724      0.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20         0G      1.864      1.323      1.415          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:09<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:51<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.761      0.669      0.749      0.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20         0G      1.845      1.277      1.396          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:09<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:51<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.763      0.699       0.75      0.325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20         0G      1.833      1.255      1.392          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:08<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:51<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.787      0.715      0.776      0.334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20         0G      1.824      1.231      1.385          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:09<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:51<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.795      0.722      0.804      0.355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20         0G      1.809      1.183      1.373          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:08<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:51<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.803      0.728      0.808      0.355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20         0G      1.788      1.159      1.362          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:09<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:51<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766       0.83      0.752      0.818      0.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20         0G      1.779      1.135      1.353          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:10<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:51<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.819      0.754      0.819      0.362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20         0G      1.767       1.12      1.344          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:10<00:00,  1.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:52<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.836      0.736       0.82      0.366\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      20/20         0G      1.748      1.083      1.339          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 387/387 [07:12<00:00,  1.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:53<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.828      0.763      0.821      0.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 2.730 hours.\n",
      "Optimizer stripped from runs\\detect\\train2\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train2\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train2\\weights\\best.pt...\n",
      "Ultralytics 8.3.136  Python-3.9.21 torch-2.7.0+cpu CPU (AMD Ryzen 5 5600 6-Core Processor)\n",
      "Model summary (fused): 72 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:45<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.827      0.763      0.821      0.368\n",
      "                     0        391        391      0.938      0.972      0.968      0.502\n",
      "                     1        389        389      0.826      0.843      0.886      0.378\n",
      "                     2        225        225       0.72      0.422       0.56      0.199\n",
      "                     3        366        366      0.811      0.702      0.788      0.376\n",
      "                     4        395        395      0.842      0.876      0.901      0.386\n",
      "Speed: 0.6ms preprocess, 22.3ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0, 1, 2, 3, 4])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000021B8A97CF70>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,    0.018434,   0.0092169,           0],\n",
       "       [          1,           1,           1, ...,    0.022164,    0.011082,           0],\n",
       "       [    0.87879,     0.87879,     0.87879, ...,   0.0009758,   0.0004879,           0],\n",
       "       [          1,           1,           1, ...,   0.0021857,   0.0010928,           0],\n",
       "       [          1,           1,           1, ...,    0.018385,   0.0091925,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.31601,     0.31601,     0.39181, ...,           0,           0,           0],\n",
       "       [    0.15723,     0.15727,     0.20459, ...,           0,           0,           0],\n",
       "       [   0.054689,      0.0547,    0.081908, ...,           0,           0,           0],\n",
       "       [   0.080045,    0.080054,     0.12112, ...,           0,           0,           0],\n",
       "       [      0.208,       0.208,     0.25276, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.18839,     0.18839,     0.24488, ...,           1,           1,           1],\n",
       "       [   0.085379,    0.085404,     0.11412, ...,           1,           1,           1],\n",
       "       [   0.028162,    0.028168,    0.042833, ...,           1,           1,           1],\n",
       "       [   0.041761,    0.041765,    0.064629, ...,           1,           1,           1],\n",
       "       [    0.11624,     0.11624,     0.14498, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.97954,     0.97954,     0.97954, ...,           0,           0,           0],\n",
       "       [    0.99229,     0.99229,     0.98715, ...,           0,           0,           0],\n",
       "       [    0.94222,     0.94222,     0.93333, ...,           0,           0,           0],\n",
       "       [    0.96175,     0.96175,     0.96175, ...,           0,           0,           0],\n",
       "       [    0.98734,     0.98734,     0.98481, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.41360125684510163\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.50172,     0.37834,     0.19936,     0.37638,     0.38608])\n",
       "names: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.8274501640077354, 'metrics/recall(B)': 0.7631157504304523, 'metrics/mAP50(B)': 0.8206312552078987, 'metrics/mAP50-95(B)': 0.3683757014714575, 'fitness': 0.41360125684510163}\n",
       "save_dir: WindowsPath('runs/detect/train2')\n",
       "speed: {'preprocess': 0.5895203284201372, 'inference': 22.33539603624, 'loss': 5.639864299147066e-05, 'postprocess': 0.29359524348487653}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO('yolov8n.pt')\n",
    "model.train(data='data.yaml', epochs=20, imgsz=416, batch=16, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.136  Python-3.9.21 torch-2.7.0+cpu CPU (AMD Ryzen 5 5600 6-Core Processor)\n",
      "Model summary (fused): 72 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 216.165.6 MB/s, size: 19.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Zaky\\Documents\\p2-final-project-ftds-hck-026\\valid\\labels.cache... 1766 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1766/1766 [00:00<?, ?it/s]\n",
      "c:\\Users\\Zaky\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:40<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1766       1766      0.827      0.763      0.821      0.368\n",
      "                     0        391        391      0.938      0.972      0.968      0.502\n",
      "                     1        389        389      0.826      0.843      0.886      0.378\n",
      "                     2        225        225       0.72      0.422       0.56      0.199\n",
      "                     3        366        366      0.811      0.702      0.788      0.376\n",
      "                     4        395        395      0.842      0.876      0.901      0.386\n",
      "Speed: 0.5ms preprocess, 20.0ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('runs/detect/train2/weights/best.pt')\n",
    "metrics = model.val(data='data.yaml', imgsz=416, batch=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
